
\section{The Poisson game}
  \begin{definition}[$(\ell, n, \alpha)$-game]\label{def:xor-game-poisson}
      Let $\ell, n, m \in \NN, \alpha \in (0, 1/2)$ and 
      $\sigma \in \RR^m$ so that $\sigma_i \in (0, 1)$ and $\sum_{i=1}^m \sigma_i = \alpha$. 
      Let $X_1, \ldots, X_m \in \{0,1\}$ be independent Bernoulli random variables with 
      $\Pr[X_i = 1] = \sigma_i$. 
      Define $S = \sum_{i = 1}^m X_i$ 
      and let $\Distribution$ be the distribution of $S$.
      Then an $(\ell, n, \Distribution)$-game is called an 
      \emph{$(\ell, n, \alpha)$-game}.
  \end{definition}


  \begin{theorem}\label{thm:xor-game-private-election}
      Let $\ell, n \in \NN, n \geq 2$ and $\alpha \in (0, 1/2)$. 
      Let
      \begin{equation}\label{eq:lambda-star-poisson}
          \lambda = \begin{cases}
              2 & \quad\text{if $\alpha \leq 0.41$\,,}\\
              \frac{2 \ln(1/\alpha)}{\ln(1+3\alpha+\alpha^2)} &\quad\text{otherwise\,.}
          \end{cases}
      \end{equation}
      Let $U$ be an $(\ell, n, \alpha)$-game with grinding power $g$. 
      Let $A$ be the event that 
      at least one of the option sets $P_{\ell + i}, i \in [n]$ in $U$ is $\{\star\}$; 
      condition on $A$. 
      Then 
      $$
          \Exp[g^\lambda \mid A] 
          \leq \frac{n^{1 + \lambda} }{1+\alpha} 
          \cdot \begin{cases}
              (1 + 3 \alpha + \alpha^2)^{\ell} &\quad\text{if $\alpha \leq 0.41$\,,} \\
              (1/\alpha)^\ell &\quad\text{otherwise\,.}
          \end{cases}
          \,.
      $$
      % \begin{align*}
      %     \Exp[g^2 \mid A] &\leq n^3 \cdot 
      %         (1 + 3 \alpha + \alpha^2)^\ell 
      %         &\qquad\text{if\quad $\alpha \in (0, 0.41]$, }\\
      %     \Exp[g^{1.37} \mid A] &\leq n^{2.37} \cdot 
      %         (1 + 3 \alpha + \alpha^2)^{0.685 \ell }
      %         &\qquad\text{if\quad $\alpha \in (0.41, 0.5)$}
      %         \,.
      % \end{align*}
  \end{theorem}
  We postpone a proof for the moment.



  \begin{lemma}\label{lemma:xor-game-poisson-gamma}
      Let $\EpsP \in (0, 1), \alpha \in (0, 1/2), \ell, n \in \NN$ and $n \geq \ell$. 
      Let $\lambda$ be defined in~\eqref{eq:lambda-star-poisson}.
      Let 
      \begin{equation}
          \label{eq:xor-poisson-tail-gamma}
          % \gamma = (1 + 3 \alpha + \alpha^2)^{\ell/2} \cdot \begin{dcases}            
          %     n^{1.50} \EpsP^{-0.50} \,,&\quad\text{if}\quad\alpha \in (0, 0.41]\,, \\
          %     n^{1.73} \EpsP^{-0.73} \,,  &\quad\text{if}\quad\alpha \in (0.41, 0.50)\,.
          % \end{dcases}
          \gamma = \left(\frac{n^{1 + \lambda} }{ (1+\alpha) \EpsP} \right)^{1/\lambda}
              \cdot \begin{cases}
                  (1 + 3 \alpha + \alpha^2)^{\ell/\lambda} &\quad\text{if $\alpha \leq 0.41$\,,} \\
                  (1/\alpha)^{\ell/\lambda} &\quad\text{otherwise\,.}
              \end{cases}
      \end{equation}
      % and $\beta = 5/(12 - 14 \alpha)$.
      Let $g$ be the grinding power in an $(\ell, n, \alpha)$-game. 
      Then $\Pr[g \geq \gamma] \leq \alpha^n + \EpsP$.
  \end{lemma}
  \begin{proof}
      Let $g$ be the grinding power of an $(\ell, n, \alpha)$-game $U$.
      Let $A$ be the event that 
      at least one of the option sets $P_{\ell + i}, i \in [n]$ in $U$ is $\{\star\}$. 
      Recall the random variable $S$ from Definition~\ref{def:xor-game-poisson}. 
      Recall that in the proof of Theorem~\ref{thm:xor-game-private-election}, 
      we established that $\Pr[S \geq 1] \leq \alpha$. 
      It follows that $\Pr[\overline{A}] = (\Pr[S \geq 1])^n \leq \alpha^n$. 
      Thus, for any non-negative real $\gamma$, 
      we have 
      $
      \Pr[g \geq \gamma] 
      \leq 1 \cdot \Pr[\overline{A}] + \Pr[g \geq \gamma \mid A] \cdot 1
      = \alpha^n + \Pr[g \geq \gamma \mid A]
      $. 
      The rest of the proof focuses on finding a $\gamma$ so that 
      for a given $\EpsP$, 
      $\Pr[g \geq \gamma \mid A]$ is at most $\EpsP$. 

      The bound in~\eqref{eq:xor-poisson-tail-gamma} follows from 
      Theorem~\ref{thm:xor-game-private-election} and the following fact.

      \begin{fact}\label{fact:grinding-max}
          Let $\GrindingPower$ be an arbitrary non-negative random variable, 
          $\EpsP \in (0, 1)$ and 
          $\GrindingMax, \lambda$ be arbitrary positive reals. 
          If $
          % \begin{equation}\label{eq:grinding-max}
              \GrindingMax \geq \left( \Exp[g^\lambda]/\EpsP \right)^{1/\lambda}
          % \end{equation}
          $
          then $\Pr[\GrindingPower \geq \GrindingMax] \leq \EpsP$.    
      \end{fact}
      \begin{proof}
          We can use Markov's inequality to write 
          $
          % \begin{equation}\label{eq:grinding-markov}
              \Pr[\GrindingPower \geq \GrindingMax] \leq \Exp[\GrindingPower^\lambda]/\GrindingMax^\lambda
          $.
          % \end{equation}
          If we require $\Pr[\GrindingPower \geq \GrindingMax] \leq \EpsP$, 
          it suffices to require 
          $\Exp[\GrindingPower^\lambda]/\GrindingMax^\lambda \leq \EpsP$, or
          $\GrindingMax^\lambda \geq \Exp[\GrindingPower^\lambda]/\EpsP$. 
          Taking the $\lambda$th root gives the lower bound on $\gamma$.
      \end{proof}
      This completes the proof of Lemma~\ref{lemma:xor-game-poisson-gamma}.
  \end{proof}


  \subsection{Proof of Theorem~\ref{thm:xor-game-private-election}.}
  % \begin{proof}
      % First, note that 
      % $\ln(\Pr[S \geq 0]) 
      % = \ln\left(\prod_{i = 1}^m (1 - \sigma_i) \right) 
      % = \sum_{i = 1}^m \ln (1 - \sigma_i)$. 
      % Since the function $x \mapsto \ln(1 -x)$ is concave and super-additive for $x \in (0, 1)$, 
      % it follows that $\ln(\Pr[S \geq 0]) \geq \ln (1 - \sum_i \sigma_i) = \ln (1 - \alpha)$. 
      % Since logarithm is a monotone function, $\Pr[S \geq 0] \geq 1 - \alpha$ and, 
      % consequently, $$\Pr[S \geq 1] \leq \alpha\,.$$
      Recall the definition of an $(\ell, n, \alpha)$-game from Definition~\ref{def:xor-game-poisson}
      and 
      the random variable $S$ therein. 
      By Markov's inequality,
      $$
          \Pr[S \geq 1] \leq \frac{\Exp S}{1} = \alpha \,.
      $$

      \paragraph{Case: $\alpha \in (0, 0.41]$.}
      Let $X'_i \in \{0,1\}, i \in [m]$ be i.i.d. Bernoulli random variables 
      with $\Pr[X'_i] = \alpha/m$. 
      Define $S' = \sum_{i=1}^m X'_i$ 
      so that $S'\sim \Binomial(m, \alpha/m)$. 
      Fact~\ref{fact:second-moment-equal-unequal-stake} states that 
      $\Exp S^2 \leq \Exp {S'}^2 \leq \alpha + \alpha^2$. 
      Since $\Exp S = \alpha$, it follows that 
      $$
      \Exp (1 + S)^2 
      \leq 1 + 2 \Exp S + \Exp S^2
      \leq 1 + 3 \alpha + \alpha^2
      \,.
      $$
      Since $\alpha < 1/2$, the quantity 
      $\Pr[S \geq 1] \cdot \Exp (1 + S)^2$ is at most $\alpha\cdot (1 + 3.5 \alpha)$. 
      This quantity is convex and increasing in $\alpha$. 
      The unique solution to the quadratic equation $3.5 \alpha^2 + \alpha - 1 = 0$ 
      for $\alpha \in (0, 1/2)$ 
      is $\alpha = (-1 + \sqrt{1 + 14})/7 = 0.4104$. 
      Therefore, for any $\alpha \leq 0.41$, 
      the random variable $S$ satisfies~\eqref{eq:lambda-S-requirement} 
      with $\lambda = 2$.
      By Lemma~\ref{lemma:adaptive-moment}, we conclude that 
      $\Exp[g^2 \mid A] \leq n^3 (1 + 3 \alpha + \alpha^2)^\ell$ 
      for $\alpha \in (0, 0.41]$.
      
      \paragraph{Case: $\alpha \in (0.41, 0.5)$.}
      In this case, we use Holder's inequality for any $\lambda \in (1,2)$ 
      and observe that 
      $$
          \Exp (1+S)^\lambda 
          \leq \left( \Exp (1+S)^2 \right)^{\lambda/2} 
          = (1 + 3\alpha +\alpha^2)^{\lambda/2}
          \,.
      $$
      Recalling~\eqref{eq:lambda-S-requirement}, 
      we want to find the maximal $\lambda \in (1, 2)$ 
      which satisfies $\alpha(1 + 3\alpha +\alpha^2)^{\lambda/2} \leq 1$ or, 
      equivalently, setting $\lambda$ as in~\eqref{eq:lambda-star-poisson}. 
      Note that this implies $\Exp (1+S)^\lambda \leq 1 + 3\alpha +\alpha^2)^{\lambda/2} \leq 1/\alpha$.
      The claim follows from applying Lemma~\ref{lemma:adaptive-moment} 
      with $\lambda$ from~\eqref{eq:lambda-star-poisson}. 
      % Since the quantity at the right-hand side increases monotonically in $\alpha$, 
      % it suffices to use $\alpha = 1/2$; that is, 
      % $$
      %     \lambda 
      %     \leq \frac{2 \log_2(1/\alpha)}{\log_2(1 + 3\alpha +\alpha^2)}
      %     \leq \frac{2}{\log_2(1 + 3/2 + 1/4)}
      %     < 1.37
      %     \,.
      % $$

      % Let $\lambda \in (1, 2)$ and $\alpha \in (0.41, 0.5)$. 
      % Define 
      % $$f(\lambda) = \Exp (1 + S)^\lambda
      % \quad \text{and} \quad
      % h(\lambda) = \Exp (1 + S')^\lambda
      % $$
      % and note that since $S, S'$ are non-negative, 
      % both $f$ and $h$ are convex combinations of 
      % convex and increasing functions in $\lambda$; 
      % hence both $f(\lambda), h(\lambda)$ are convex and increasing in $\lambda$. 
      % Moreover, $f(1) = h(1) = \alpha$ and $f(2) \leq h(2) = \alpha + \alpha^2$. 
      % It follows that $f(\lambda) \leq h(\lambda)$ for $\lambda \in (1, 2]$ or, 
      % equivalently, $\Exp (1 + S)^\lambda \leq \Exp (1 + S')^\lambda$.

      % It is a known fact (and easy to check) that $\Binomial(m, \alpha/m) \DominatedBy \Poisson(\alpha)$. 
      % Let $P \sim \Poisson(\alpha)$ and note that $S' \sim \Binomial(m, \alpha/m)$. 
      % Hence $$\Exp (1 + S)^\lambda \leq \Exp (1 + P)^\lambda\,.$$ 
  \hfill\qed




































\section{The Poisson game over multiple epochs}



% Therefore, we cannot achieve both a small $\rho$ and a small $\epsilon$ at the same time. 
% If we wish to give a strong guarantee we have to use a large $\tau$, 
% but the min-entropy loss $\rho$ depends linearly on $\tau$. 

Let $\tau > 0$ and $\alpha \in (0, 1/2)$ be two reals. 
 % and $\EpsP = 2^{-\tau}$. 
Let $\EpsP \in (0, 1)$. 
Let $d, k \in \NN$ 
so that $d$ divides $k$. 
Let $R \in \NN, T = Rk$ so that 
writing $n = (T - k)/d$ and $\ell = k/d$, 
$\alpha^n$ is at most $\EpsP$. 
Let $\Blockchain$ be an $(\EpsP, k, s)$-secure blockchain protocol 
with epoch length at least $T + s + k$. 
Suppose the	coin-flipping protocol $\Pi = \CoinTossingPrivate$ 
takes place in the first $T$ slots of every epoch. 
That is, the coin-flipping output of an epoch is used 
as the input for the coin-flipping in the next epoch; 
the input to the first epoch is a uniformly random string. 
The parameter $d$ of $\Pi$ is given below.
Let the coin-flipping outcome after $L$ epochs of $\Blockchain$ is $\eta$.

\begin{theorem}\label{thm:beacon-poisson}
	Let $\alpha \in (0, 0.41)$. 
	Let $\lambda$ be defined in~\eqref{eq:lambda-star-poisson} and 
	let $\gamma$ be defined in~\eqref{eq:xor-poisson-tail-gamma}. 
	Let 
	$$
			d = \lfloor (T - k) \log_2(1/\alpha)/\log_2(1/\EpsP)\rfloor
			\,,\quad
			f(\alpha) = \frac{\ln(1 + 3 \alpha + \alpha^2)}{\ln(1/\alpha)}
			\,,\text{and}
	$$
	% and
	\begin{equation}\label{eq:delta-prob-loss-multiepoch}
		\delta 
		= 
			1/2 - \frac{(3/2) \log_2(T - k)}{\tau} 
			- \frac{k \alpha}{0.82 (T - k)}
      \,.
	\end{equation}
	Then 
	$$
		\Pr\left[\MinEntropy(\eta) \geq \kappa - \log_2(\gamma)\right] \geq 1 -  3 L \EpsP^\delta
		\,.
	$$
	% where the probability is taken over 
	% the leader election mechanism.
\end{theorem}

% \iftoggle{drawfigs}{

\begin{figure}
  \centering
  \pgfmathsetmacro{\k}{900}
  \pgfmathsetmacro{\d}{1}
  \pgfmathsetmacro{\R}{16} % 0.6 * epoch length
  % \pgfmathsetmacro{\T}{\R * \k}
  % \pgfmathsetmacro{\tau}{\k/2}
  \pgfmathsetmacro{\s}{\k}
  % \pgfmathsetmacro{\n}{(\R - 1) * \k/\d}
  % \pgfmathsetmacro{\ell}{\k/\d}
  % \pgfmathsetmacro{\ellPlusN}{\ell + \n}
  \begin{tikzpicture}[trim axis left,
    declare function={
    	eps(\a) = 1 - 2 * \a;
    	tau(\eps) = \eps^3 * (1 - \eps) * log2(exp(1)) * \k;
    	%----------- Praos beacon----------------
    	phi(\eps) = (3/2) * (1 + \eps)^(1/3) * ( 1 - \eps)^(2/3);
    	praos_delta(\a) = 0.5 - 0.5 * (
    		log2(\s^2 * 2^(-1.3 + 1.85 * eps(\a))  ) 
    		+ \s * log2( 
	    		\a > 1/3 ? ((5 - 3 * eps(\a))/2) : (
	    		\a > 0.2 ? (2^(2/3) * phi(eps(\a))) : (
	    		\a > 0.0955 ? ((5/3) * phi(eps(\a))) : 	(1)
			) ) ) )/tau(eps(\a));
    	%----------- New beacon ----------------
			moment(\a) = 
				\a <= 0.41 
				? (1 + 3 * \a + \a^2)
				: 1/\a;
			lambda(\a) = 
				\a <= 0.41 
				? 2 
				: 2 * ln(1/\a) / ln(1 + 3 * \a + \a * \a);
			n(\a) = tau(eps(\a)) / log2(1/\a);
			ell(\a) = n(\a) / (\R-1);
      f(\a) = 2 / lambda(\a);
      %
      new_beacon_delta(\a) = 
				1 - 1/lambda(\a) 
					- (
						ell(\a)/lambda(\a) * log2( moment(\a) )
			      + (1 + 1/lambda(\a)) * log2( n(\a) )
		    	)/tau(eps(\a));
		  % new_beacon_delta(\a) = 
      % 	1 - 1/lambda(\a) - ( 
      % 		( ell(\a) / lambda(\a) ) * log2(	moment(\a) ) 
		    % 		+ (1 + 1/lambda(\a) )  * log2( n(\a) ) 
      % 	)/ tau(eps(\a));
    }
    %    declare function = { entropy(\x) = 1; },
    ]
    \begin{axis}[domain=0:0.5,
      restrict x to domain=0:0.41,
      xmin=0, xmax=0.5,
      samples=100,
      enlarge x limits=false,
      grid=both,
      no markers,
      % ymin=0,
      % ymax=1,
      % x label style={at={(axis description cs:0.5,-0.1)},anchor=north},
      % y label style={at={(axis description cs:0,.5)},anchor=south},
      xlabel={$\alpha$, relative adversarial stake},
      ylabel={$\delta$},
      % there is one default value for the `legend pos' that is outside the axis
      legend pos=outer north east,
      % (so the legend looks a bit better)
      legend cell align=left
      ]
      % \addplot +[thick,domain=0:(0.0955),red,forget plot] plot (\x, {rho_praos_small_alpha(\x)});
      % \addplot +[thick,domain=0.0955:(1/3),red,forget plot] plot (\x, {rho_praos_mid_alpha(\x)});
      % \addplot +[thick,domain=(1/3):(0.5),red,legend] plot (\x, {rho_praos_large_alpha(\x)});
      % \addlegendentry{Praos, $\ellPlusN$ rounds}

      % \addplot +[thick,domain=0:(1/3),blue,forget plot] plot (\x, {rho_geom_small_alpha(\x)});
      % \addplot +[thick,domain=(1/3):(1/2),blue,legend] plot (\x, {rho_geom_large_alpha(\x)});
      % \addlegendentry{$(\ell, \n, \alpha)$-geometric game, $d = 1$}

      \addplot +[thick,domain=(0.001):(0.41),blue] plot (\x, {new_beacon_delta(\x)});
      \addlegendentry{New beacon}

      % \addplot +[thick,domain=(0):(1/2),red] plot (\x, {praos_delta(\x});
      % \addlegendentry{Praos beacon, $s = k$}

    \end{axis}
  \end{tikzpicture}
  \caption{Plot of $\delta$ from~\eqref{eq:delta-prob-loss-multiepoch} using $k = 900, T = 24k, s = k/4,$ and $\EpsP = 2^{-k/3}$.}
  \label{fig:poisson-beacon}
\end{figure}

% } % end iftoggle{drawfigs}



\newcommand{\dMin}{d_\mathrm{min}}
\newcommand{\dMax}{d_\mathrm{max}}

\subsection{Proof of Theorem~\ref{thm:beacon-poisson}}
	% Suppose $\Pi$ is $(p, \rho)$-secure. 
	% Since the ledger protocol $\Blockchain$ is $(2^{-\tau}, k)$-secure, 
	% Lemma~\ref{prop:coin-tossing-security-private} states that 
	% $\rho$ is given by~\eqref{eq:minentropy-loss-poisson} 
	% where we use $\EpsP = 2^{-\tau}$. 
	% It also states that 
	% $p = \alpha^n + 2 \cdot 2^{-\tau} \leq 3 \cdot 2^{-\tau}$ 
	% since $\alpha^n \leq 2^{-\tau}$. 
	% Next, Lemma~\ref{lemma:composition} states that 
	% an $(L, \Pi)$-composition must be $(2^\rho p L, \rho)$-secure.

	Let $\ell = k/d$ and $n = (T - k)/d$. 
	Let $\tau = \log_2(1/\EpsP)$. 
	Let 
	$$
    a = \begin{cases}
        1 + 3 \alpha + \alpha^2 &\quad\text{if $\alpha \leq 0.41$\,,} \\
        1/\alpha &\quad\text{otherwise\,,}
    \end{cases}
	$$
	and 
	$$
		p(d) = n^{1+1/\lambda} \EpsP^{1 - 1/\lambda} a^{\ell/\lambda}
		\,.
	$$
	Then the total failure probability in Lemma~\ref{lemma:composition} is at most $3 L p(d)$.	
	Let $\delta \in (0, 1)$ so that $p(d) \leq \EpsP^\delta$; 
	the value of $\delta$ will be determined later. 
	We wish to select a $d$ so that $\delta$ is maximized.

	First, we require that 
	\begin{align*}
		&\alpha^n \leq \EpsP\,,\\
		\text{or}\quad &
			1/\EpsP \leq (1/\alpha)^{(T - k)/d}\,,\\
		\text{or}\quad &
			\log_2(1/\EpsP) \leq ((T - k)/d)\log_2(1/\alpha)\,,\\
		\text{or}\quad &
			d \leq \dMax \triangleq \frac{(T - k)\log_2(1/\alpha)}{\log_2(1/\EpsP)}
			\,.
	\end{align*}

	We also want 
	\begin{align*}
		&p(d) \leq \EpsP^{\delta}\,,\\
		\text{or}\quad &
			n^{1+1/\lambda} \EpsP^{1 - 1/\lambda} a^{\ell/\lambda} \leq \EpsP^\delta \,,\\
		\text{or}\quad &
			(1+1/\lambda)\log_2(n)
			+ (1/\lambda - 1)\log_2(1/\EpsP) 
			+ (\ell/\lambda) \log_2(a) \leq -\delta \log_2(1/\EpsP) \,,\\
		\text{or}\quad &			
			(\ell/\lambda) \log_2(a) \leq (1-\delta - 1/\lambda) \log_2(1/\EpsP) - (1+1/\lambda)\log_2(n)\,,\\
		\text{or}\quad &			
			(k/d\lambda) \log_2(a) \leq (1-\delta - 1/\lambda) \log_2(1/\EpsP) - (1+1/\lambda)\log_2((T-k)/d)\,,\\
		\text{or}\quad &			
			\frac{(k/\lambda) \log_2(a)}{(1-\delta - 1/\lambda) \log_2(1/\EpsP) - (1+1/\lambda)\log_2((T-k)/d)} \leq d
			\,.
	\end{align*}
	
	For the above inequality to hold, 
	it suffices to take $d \geq \dMin(\delta)$ where 
	$$
		\dMin(\delta) = \frac{(k/\lambda) \log_2 a}{(1 - \delta - 1/\lambda) \log_2(1/\EpsP) - (1+1/\lambda) \log_2(T - k)}
		\,.
	$$
	An admissible $d$ must satisfy
	\begin{align*}
		&\dMin(\delta) \leq \dMax	\,,\\
		\text{or}\quad &			
			\frac{(k/\lambda) \log_2 a}{(1 - \delta - 1/\lambda) \log_2(1/\EpsP) - (1+1/\lambda) \log_2(T - k)}
				\leq (T - k) \log_2(1/\alpha)/\log_2(1/\EpsP) \,,\\
		\text{or}\quad &			
			\frac{(k/\lambda) \log_2 a}{(T - k) \log_2(1/\alpha)/\log_2(1/\EpsP)} 
				\leq (1 - \delta - 1/\lambda) \log_2(1/\EpsP) - (1+1/\lambda) \log_2(T - k) \,,\\
		\text{or}\quad &			
			\frac{(k/\lambda) \log_2 a}{(T - k) \log_2(1/\alpha)} + \frac{(1+1/\lambda) \log_2(T - k)}{\log_2(1/\EpsP)}
				\leq 1 - \delta - 1/\lambda  \,,\\
		\text{or}\quad &			
			\frac{(1/\lambda) \log_2 a}{(R - 1) \log_2(1/\alpha)} + \frac{(1+1/\lambda) \log_2(k(R-1))}{\log_2(1/\EpsP)}
				\leq 1 - \delta - 1/\lambda  
				\,.
	\end{align*}
	Therefore, if we take $d = \lfloor \dMax \rfloor$ we can achieve  $p(d) \leq \EpsP^{\delta}$ 
	where 
	\begin{equation}\label{eq:delta}
		\delta
			\leq 1 - 1/\lambda - \frac{(1/\lambda) \log_2 a}{(R-1) \log_2(1/\alpha)} - \frac{(1+1/\lambda) \log_2(k(R-1))}{\log_2(1/\EpsP)}  
	\end{equation}

	\paragraph{Case: $\alpha \leq 0.41$.} 
	We use $a = 1 + \alpha + \alpha^2, \lambda = 2$, and 
	$$ 
		f(\alpha) = \ln(1 + \alpha + \alpha^2)/\ln(1/\alpha)
	$$
	to get 
	$$
	\delta = 
		1/2 
			- \frac{f(\alpha)/2}{R - 1} 
			- \frac{(3/2) \log_2(k(R-1))}{\log_2(1/\EpsP)}
			\,.
		% = 1 - \frac{\ln(1+3\alpha+\alpha^2)}{2 \ln(1/\alpha)} 
		% 		- \left(1 + \frac{\ln(1+3\alpha+\alpha^2)}{2 \ln(1/\alpha)}\right) \log_2(T - k)/\tau 
		% 		- \frac{k\ln(1+3\alpha+\alpha^2)}{2 (T - k) \ln(1/\alpha)} 
		% 			&\quad\text{otherwise\,.}
	$$
	{\color{blue}We can check that }
	$f(\alpha)$ is convex and increasing for $\alpha \in (0, 0.41]$; 
	hence the linear upper bound 
	$f(\alpha) \leq \alpha/0.41$ holds. 
	Therefore, it is sufficient to take 
	\begin{align*}
		&\delta 
			\leq 
			\frac{1}{2} 
				- \frac{\alpha}{0.82 (R - 1)} 
				- \frac{(3/2) \log_2(k(R-1))}{\log_2(1/\EpsP)} 
				\,, \\
		\text{or}\quad&\delta \leq \frac{1}{2} 
				- \frac{1.22 \alpha}{R - 1} 
				- \frac{(3/2)\log_2(k(R-1))}{\log_2(1/\EpsP)} 
				\,.		
	\end{align*}

	\hfill\qed





% %--------------------------------------------------------------
% % \begin{theorem}[Composing $(\ell, n, \alpha)$-Bernoulli games]\label{thm:xor-game-beacon}
% % 	Let $\EpsP, \delta \in (0,1), \alpha \in (0, 1/2)$, 
% % 	and $L, \kappa \in \NN$ be arbitrary parameters. 
% % 	Set $q = \log_2(1/\EpsP)$, 
% % 	$\lambda = \log_2(1/\alpha)$, 
% % 	$n = q/\lambda$,  
% % 	$\ell \leq q(1 - \delta - 1/\lambda) - (3 + \log_2 n)$,
% % 	% $\ell \leq q(1 - \delta - 1/\lambda) - 3 - \log_2(q/\lambda)$,
% % 	and $N = \ell + n$.
% % 	Consider an $(L, N, \kappa)$-composition (cf. Definition~\ref{def:composition}) 
% % 	of the $(\ell, n, \alpha)$-Bernoulli game  
% % 	with a uniformly random value. 
% % 	The min-entropy of this composition 
% % 	is at least $\kappa - \left(\ell + 1 + n + \log_2(n) \right)$, 
% % 	except with probability at most $\EpsP^\delta$. 
% % 	% In particular, $\delta \in (0,1)$ if $\ell < q - 3 - n - \log_2(L n)$.
% % \end{theorem}
% % \begin{proof}
% % 	First, we claim that the prerequisite $\EpsA \leq \EpsP$ 
% % 	in the Composition Lemma (Lemma~\ref{lemma:composition}) holds. 
% % 	This is because (i.) $\EpsA = \alpha^{n+\ell} \leq \alpha^n$ by 
% % 	the independence of the Bernoulli random variables $Z_i$s, and 
% % 	(ii.) setting $n = q/\lambda$ implies $\alpha^n = \EpsP$.  

% % 	Next, observe that the expression of $\delta$ in~\eqref{eq:delta-composition-generic} stays the same 
% % 	even if we use the base-$2$ logarithm instead of the natural logarithm. 
% % 	In addition, notice that $1/\lambda = n/q$ by design and 
% % 	$(1/\lambda) \log_2 \Exp g^\lambda = \ell + 1 + (\log_2(n))/\lambda$ 
% % 	by Lemma~\ref{lemma:xor-game-bernoulli-moment}.
% % 	By the Composition Lemma, the error probability is at most $L \EpsP^{\delta^\prime}$ 
% % 	where
% % 	$\delta^\prime = 1 - (n + \ell + 1 + \log_2(3 n)/\lambda)/q$. 
% % 	It is easy to see that $\delta^\prime < 1$.
% % 	Since $\alpha < 1/2$, we have $\lambda > 1$ and consequently, we can take
% % 	$\hat{\delta} = 1 - (n + \ell + 1 + \log_2(3 n))/q < \delta^\prime < 1$. 
% % 	This choice implies $\EpsP^{\hat{\delta}}$ is an upper bound on the failure probability $\EpsP^{\delta^\prime}$. 

% % 	However, we can change the order of choosing $\hat{\delta}$ and $\ell$. 
% % 	Namely, the above choice of $\hat{\delta}$ and $\ell$ is equivalent to first choosing 
% % 	an arbitrary $\delta \in (0, 1)$ and then choosing an $\ell \in \NN$, 
% % 	as a function of $n, q$, and $\delta$, 
% % 	satisfying $\ell \leq q(1 - \delta) - (n + \log_2(3 n) + 1)$. 
% % 	It follows that the failure probability $\EpsP^{\delta^\prime}$ is at most $\EpsP^\delta$. 
% % 	This bound on $\ell$ means it suffices to take 
% % 	$\ell \leq  q(1 - \delta - 1/\lambda) - (3 + \log_2(n))$ 
% % 	since $n = q/\lambda$ and $1 + \log_2(3) < 3$.

% % 	The min-entropy bound in the claim follows from using the expression of $\gamma$ from
% % 	Lemma~\ref{lemma:xor-game-bernoulli-gamma} 
% % 	into Corollary~\ref{coro:composition-min-entropy}. 
% % \end{proof}


% \subsection{Min-entropy of a composition of \texorpdfstring{$(\ell, n, \alpha)$-}{}geometric games}
% \begin{theorem}[Composing $(\ell, n, \alpha)$-geometric games]\label{thm:xor-game-beacon-geometric}
% 	Let $\EpsP, \delta \in (0,1), \alpha \in (0, 1/2)$, 
% 	and $L, \kappa \in \NN$ be arbitrary parameters. 
% 	Define $\beta = \beta(\alpha)$ and $c = c(\alpha)$ as
% 	\[
% 		\begin{cases}
% 			\beta = 1/2,\, c = \sqrt{e}
% 				\,,&\qquad\text{if}\quad \alpha \in (0, 1/4]\,, \\
% 			\beta = 2/3,\, c = 0.85
% 				\,,&\qquad\text{if}\quad \alpha \in (1/4, 1/3]\,, \\
% 			\beta = 5/(12 - 14 \alpha),\, c = (1.67 + 2.66 \alpha)/3^\beta
% 				\,,&\qquad\text{if}\quad \alpha \in (1/3, 1/2)\,.
% 		\end{cases}
% 	\]	
% 	Set
% 	% $\lambda = \log_2(1/\alpha)$, 
% 	\begin{align*}
% 		q = \log_2(1/\EpsP)\,, \quad 
% 		n = \frac{q}{\log_2(1/\alpha)}\,,\quad\text{and}\quad
% 		\ell \leq
% 			\frac{q(1 - \beta - \delta ) - \log_2(3 n 5^\beta)}{\log_2(c) - \log_2(1-\alpha)}
% 			\,.
% 	\end{align*}
% 	% $\ell \leq q(1 - \delta - 1/\lambda) - 3 - \log_2(q/\lambda)$,
% 	Let $U$ be an $(\ell, n, \alpha)$-geometric game 
% 	on strings in $\{0,1\}^\kappa$. 
% 	With probability at least $1 - L \EpsP^\delta$,
% 	the min-entropy loss in 
% 	an $(L, G)$-composition 
% 	% (cf. Definition~\ref{def:composition}) 
% 	is at most 
% 	\[
% 		\beta q + \ell \log_2\left( c / (1 - \alpha)\right) + \log_2(n 5^\beta)
% 		\,.
% 	\]
% \end{theorem}

% \begin{proof}
% 	First, we claim that the prerequisite $\Pr[A_1] \leq \EpsP$ 
% 	in Lemma~\ref{lemma:composition} holds. 
% 	Let $X \sim \GeomAlpha$ and recall that 
% 	the size of an option set is stochastically dominated by $X$.
% 	Since $\Pr[X \geq 2] = \alpha$, the probability that 
% 	each of $n$ independent copies of $X$ is at least two, 
% 	is $\alpha^n$. 
% 	Since $n = q/\log_2(1/\alpha)$ by design, 
% 	it follows that $\alpha^n = \EpsP$.  

% 	The remainder of the proof is similar to 
% 	the proof of Theorem~\ref{thm:xor-game-beacon-bernoulli}. 
% 	The only variation is that we take $\gamma$ from~\eqref{eq:xor-geom-tail-gamma}.	
% \end{proof}







